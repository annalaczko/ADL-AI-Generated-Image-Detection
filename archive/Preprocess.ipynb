{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a5de98-cec0-4352-9ef5-2cca0c2f63d1",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f33831-cf5e-46c1-9cee-669f2c632c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import shutil\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62a5e36-56aa-4eab-b5c3-72838cfb2ce5",
   "metadata": {},
   "source": [
    "# Preparation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2572f571-c4a7-421f-b3d0-bc6388913a63",
   "metadata": {},
   "source": [
    "Some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c66aac-0a2c-42c5-a846-52a9e3238ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = \"data/raw/140k face\"\n",
    "PROCESSED_DIR = \"data/processed\"\n",
    "\n",
    "CATEGORIES = [\"fake\", \"real\"]\n",
    "TRAIN_DIR = os.path.join(PROCESSED_DIR, \"train/rgb\")\n",
    "VALID_DIR = os.path.join(PROCESSED_DIR, \"valid/rgb\")\n",
    "TEST_DIR = os.path.join(PROCESSED_DIR, \"test/rgb\")\n",
    "\n",
    "SHARPEN_TRAIN_DIR = os.path.join(PROCESSED_DIR, \"train/sharpen\")\n",
    "SHARPEN_VALID_DIR = os.path.join(PROCESSED_DIR, \"valid/sharpen\")\n",
    "SHARPEN_TEST_DIR = os.path.join(PROCESSED_DIR, \"test/sharpen\")\n",
    "\n",
    "EDGE_TRAIN_DIR = os.path.join(PROCESSED_DIR, \"train/edge\")\n",
    "EDGE_VALID_DIR = os.path.join(PROCESSED_DIR, \"valid/edge\")\n",
    "EDGE_TEST_DIR = os.path.join(PROCESSED_DIR, \"test/edge\")\n",
    "\n",
    "train_ratio = 0.7\n",
    "val_ratio = 0.2\n",
    "random.seed(12347556)\n",
    "\n",
    "AUG_AMOUNT=0 #the amount of augmented version of each pictures. Turned of because of the overwhelming amount of pictures existing already\n",
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2aba8e6-e9d5-4d20-b7e3-90a90771b49c",
   "metadata": {},
   "source": [
    "Delete the whole processed_dir structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1418f296-507a-44fd-9952-6d1123d8a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we delete the whole \n",
    "\n",
    "if os.path.exists(PROCESSED_DIR):\n",
    "         shutil.rmtree(PROCESSED_DIR )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51b835f-7254-42e7-8892-220d21a10558",
   "metadata": {},
   "source": [
    "# Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2eb700-8113-4bd9-940c-7688f98e6e7d",
   "metadata": {},
   "source": [
    "The transformation structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950e6e3b-e9a2-46cb-8895-ee5858e2537c",
   "metadata": {},
   "source": [
    "Processing normal images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec525a5f-7c9b-4500-ab14-d8751564d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_label(label, size):\n",
    "    print(f\"Working on {label}\")\n",
    "    raw_path = os.path.join(RAW_DIR, label)\n",
    "    processed_path = PROCESSED_DIR\n",
    "    os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "    image_paths = [os.path.join(raw_path, f) for f in os.listdir(raw_path) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    random.shuffle(image_paths)\n",
    "    \n",
    "    # Calculate the split index\n",
    "    train_split_index = int(len(image_paths) * train_ratio)\n",
    "    val_split_index = int(len(image_paths) * (train_ratio + val_ratio))\n",
    "\n",
    "    train_paths = image_paths[:train_split_index]\n",
    "    val_paths = image_paths[train_split_index:val_split_index]\n",
    "    test_paths = image_paths[val_split_index:]\n",
    "\n",
    "    create_images(train_paths, \"train\", size, label)\n",
    "\n",
    "    create_images(val_paths, \"valid\", size, label)\n",
    "\n",
    "    create_test(test_paths, \"test\", size, label)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d1adf3e-cf8a-4366-ab2e-4d01d47b7ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_filename(base_path, base_name, counter):\n",
    "\n",
    "    image_name=f\"{base_name}_{counter}.jpg\"\n",
    "    \n",
    "    while True:\n",
    "        filename = os.path.join(base_path, image_name)\n",
    "        if not os.path.exists(filename):\n",
    "            return image_name\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96f3f864-4b3a-4abd-a1a0-7a4b5b92b66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_images(images, category, size, label):\n",
    "\n",
    "    resize_transform = transforms.Compose([\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    \n",
    "    augmentation_transforms = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size, scale=(0.7, 0.9)),\n",
    "        transforms.RandomApply([\n",
    "            transforms.ColorJitter(contrast=0.5) \n",
    "        ], p=0.5),\n",
    "        transforms.Resize(size),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    save_transform = transforms.ToPILImage()\n",
    "\n",
    "\n",
    "\n",
    "    ROOT_DIR=os.path.join(PROCESSED_DIR, f\"{size[0]}\")\n",
    "    \n",
    "    if (category==\"train\"):\n",
    "        rgb_path=os.path.join(ROOT_DIR, \"train/rgb\")\n",
    "        edge_path=os.path.join(ROOT_DIR, \"train/edge\")\n",
    "        sharpen_path=os.path.join(ROOT_DIR, \"train/sharpen\")\n",
    "    elif(category==\"valid\"):\n",
    "        rgb_path=os.path.join(ROOT_DIR, \"valid/rgb\")\n",
    "        edge_path=os.path.join(ROOT_DIR, \"valid/edge\")\n",
    "        sharpen_path=os.path.join(ROOT_DIR, \"valid/sharpen\")\n",
    "    else:\n",
    "        rgb_path=os.path.join(ROOT_DIR, \"test/rgb\")\n",
    "        edge_path=os.path.join(ROOT_DIR, \"test/edge\")\n",
    "        sharpen_path=os.path.join(ROOT_DIR, \"test/sharpen\")\n",
    "\n",
    "    os.makedirs(rgb_path, exist_ok=True)\n",
    "\n",
    "    image_counter=0\n",
    "    for i in tqdm(range(0, len(images), BATCH_SIZE), desc=f\"Processing {category}\"): #len(images)\n",
    "        batch = images[i:i + BATCH_SIZE]\n",
    "        for img_path in batch:\n",
    "\n",
    "            img = Image.open(img_path).convert(\"RGB\")  # Kép betöltése\n",
    "\n",
    "            resized_img_name = get_unique_filename(rgb_path, label, image_counter)\n",
    "\n",
    "                # Save a simple resized version\n",
    "            resized_img = resize_transform(img)\n",
    "            make_filters(resized_img, resized_img_name , edge_path, sharpen_path)\n",
    "            resized_img = save_transform(resized_img)\n",
    "\n",
    "\n",
    "            resized_img_path=os.path.join(rgb_path, resized_img_name)\n",
    "                \n",
    "            resized_img.save(resized_img_path)\n",
    "\n",
    "\n",
    "                \n",
    "            image_counter += 1\n",
    "\n",
    "            if (category==\"train\"):\n",
    "                for aug_idx in range(AUG_AMOUNT):\n",
    "                    aug_img_name= get_unique_filename(rgb_path, label, image_counter)\n",
    "                    \n",
    "                    aug_img = augmentation_transforms(img)  # Apply augmentation\n",
    "                    make_filters(aug_img, aug_img_name , edge_path, sharpen_path)\n",
    "    \n",
    "                    \n",
    "                    aug_img = save_transform(aug_img)  # Convert tensor to PIL image\n",
    "    \n",
    "    \n",
    "                    aug_img_path=os.path.join(rgb_path, aug_img_name)\n",
    "                        \n",
    "                    aug_img.save(aug_img_path)\n",
    "    \n",
    "                        \n",
    "                    image_counter += 1\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3857f830-cc92-4267-a52f-dbbfe2647391",
   "metadata": {},
   "source": [
    " move data into respective folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c4afca-9d8a-4e70-be56-e318e5121cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_filters(tensor_image, filename, edge_path, sharpen_path):\n",
    "\n",
    "    image = tensor_image.permute(1, 2, 0).numpy()\n",
    "\n",
    "    os.makedirs(edge_path, exist_ok=True)\n",
    "    os.makedirs(sharpen_path, exist_ok=True)\n",
    "    \n",
    "    kernel_edge = np.array([[-1, -1, -1],\n",
    "                            [-1, 8, -1],\n",
    "                            [-1, -1, -1]])\n",
    "\n",
    "\n",
    "    kernel_sharpen = np.array([ [0, -1, 0],\n",
    "                                [-1, 5, -1],\n",
    "                                [0, -1, 0]])\n",
    "    \n",
    "    # Apply Edge Detection filter\n",
    "    edge_result = cv2.filter2D(image, -1, kernel_edge)\n",
    "\n",
    "    # Save the Edge Detection filtered image\n",
    "    edge_output_path = os.path.join(edge_path, filename)\n",
    "    cv2.imwrite(edge_output_path, edge_result)\n",
    "\n",
    "    # Apply Sharpen filter\n",
    "    sharpen_result = cv2.filter2D(image, -1, kernel_sharpen)\n",
    "\n",
    "    # Save the Sharpen filtered image\n",
    "    sharpen_output_path = os.path.join(sharpen_path, filename)\n",
    "    cv2.imwrite(sharpen_output_path, sharpen_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d71203a-b7c3-4b56-8eaf-2a8ecc5f3976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on fake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train:  32%|███▏      | 36/112 [08:19<17:34, 13.88s/it]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cat \u001b[38;5;129;01min\u001b[39;00m CATEGORIES:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mprocess_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 19\u001b[0m, in \u001b[0;36mprocess_images\u001b[1;34m(label, size)\u001b[0m\n\u001b[0;32m     16\u001b[0m val_paths \u001b[38;5;241m=\u001b[39m image_paths[train_split_index:val_split_index]\n\u001b[0;32m     17\u001b[0m test_paths \u001b[38;5;241m=\u001b[39m image_paths[val_split_index:]\n\u001b[1;32m---> 19\u001b[0m \u001b[43mcreate_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m create_images(val_paths, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m, size, label)\n",
      "Cell \u001b[1;32mIn[5], line 54\u001b[0m, in \u001b[0;36mcreate_images\u001b[1;34m(images, category, size, label)\u001b[0m\n\u001b[0;32m     49\u001b[0m resized_img \u001b[38;5;241m=\u001b[39m save_transform(resized_img)\n\u001b[0;32m     52\u001b[0m resized_img_path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(rgb_path, resized_img_name)\n\u001b[1;32m---> 54\u001b[0m \u001b[43mresized_img\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresized_img_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m image_counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (category\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ADL\\lib\\site-packages\\PIL\\Image.py:2320\u001b[0m, in \u001b[0;36mImage.save\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2317\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2319\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2320\u001b[0m     \u001b[43msave_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   2322\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m open_fp:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ADL\\lib\\site-packages\\PIL\\JpegImagePlugin.py:783\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, filename)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# The EXIF info needs to be written as one block, + APP1, + one spare byte.\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;66;03m# Ensure that our buffer is big enough. Same with the icc_profile block.\u001b[39;00m\n\u001b[0;32m    781\u001b[0m bufsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(ImageFile\u001b[38;5;241m.\u001b[39mMAXBLOCK, bufsize, \u001b[38;5;28mlen\u001b[39m(exif) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m5\u001b[39m, \u001b[38;5;28mlen\u001b[39m(extra) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 783\u001b[0m \u001b[43mImageFile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjpeg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ADL\\lib\\site-packages\\PIL\\ImageFile.py:524\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[0;32m    521\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    522\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    523\u001b[0m         \u001b[38;5;66;03m# slight speedup: compress to real file object\u001b[39;00m\n\u001b[1;32m--> 524\u001b[0m         s \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m s \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder error \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m when writing image file\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "for cat in CATEGORIES:\n",
    "    process_images(cat, (64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2456a3-a77c-4f89-a7b1-c0e6e25509c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on fake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 112/112 [21:04<00:00, 11.29s/it]\n",
      "Processing valid: 100%|██████████| 32/32 [06:08<00:00, 11.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on real\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 49/49 [09:40<00:00, 11.84s/it]\n",
      "Processing valid: 100%|██████████| 14/14 [02:34<00:00, 11.05s/it]\n"
     ]
    }
   ],
   "source": [
    "for cat in CATEGORIES:\n",
    "    process_images(cat, (128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281ee5fd-12db-4ed4-a90b-6de3fcaf9bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on fake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 112/112 [33:17<00:00, 17.84s/it]\n",
      "Processing valid: 100%|██████████| 32/32 [09:19<00:00, 17.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on real\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 49/49 [15:29<00:00, 18.96s/it]\n",
      "Processing valid: 100%|██████████| 14/14 [04:08<00:00, 17.73s/it]\n"
     ]
    }
   ],
   "source": [
    "for cat in CATEGORIES:\n",
    "    process_images(cat, (256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d592be-3816-4e81-a229-e3b6cf7517c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ADL with GPU",
   "language": "python",
   "name": "adl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
