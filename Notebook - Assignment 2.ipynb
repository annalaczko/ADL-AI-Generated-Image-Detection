{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea5abb8-37f7-4f50-aa31-d97d9bba7e91",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d09db337-74e0-4656-af9a-6572d63b9995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\annal\\anaconda3\\envs\\jupyterlab\\lib\\site-packages (from opencv-python) (2.2.1)\n",
      "Using cached opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93ef624d-fc84-4a53-9e6d-291f68c2b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from Preprocess import Process\n",
    "from NeuralNetworkDIY import ClassifierNetwork, Model\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86229287-fe04-47b7-84be-70862133e1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce29e2-f3bd-4546-a98b-c086fe09808e",
   "metadata": {},
   "source": [
    "# Parameters for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba70bb57-9fca-49dc-a9a5-482a7dfd5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = \"data/raw\"\n",
    "PROCESSED_DIR = \"data/processed\"\n",
    "IMAGE_SIZE=(128,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3d7d9-22cb-4375-8fe5-f80f5e95ddcd",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa1a1c1-e505-468e-be4e-e19c9d0e3962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on fake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train:   0%|          | 0/112 [00:07<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "process=Process(RAW_DIR, PROCESSED_DIR, IMAGE_SIZE, delete_process_dir=True, batch_size=1000, aug_amount=0, filters=False)\n",
    "process.run(0.7, 0.3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e4d71-78dd-4d6a-b6aa-069188c23c3e",
   "metadata": {},
   "source": [
    "# DataLoader and Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21abdd73-fc67-4085-88c6-698059ea38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.image_paths = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        transform = transforms.ToTensor()\n",
    "        \n",
    "        img= transform(img)\n",
    "        # Extract label from the filename (fake -> 1, real -> 0)\n",
    "        label = 1 if \"fake\" in os.path.basename(img_path).lower() else 0\n",
    "\n",
    "        return img, label, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db67dc5-5aec-4e72-99ae-572fcf680ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomImageDataset(directory=f'{PROCESSED_DIR}/{IMAGE_SIZE[0]}/train/rgb')\n",
    "valid_data = CustomImageDataset(directory=f'{PROCESSED_DIR}/{IMAGE_SIZE[0]}/valid/rgb')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1000, shuffle=True) #batchsize set to 1000, GPU can handle it, maybe more too\n",
    "valid_loader = DataLoader(valid_data, batch_size=1000, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1a777-5745-435a-9024-3786b1611ddd",
   "metadata": {},
   "source": [
    "# Creating the network, model, training, predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286121d-f4ff-4c8f-a121-85026df1fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "network=ClassifierNetwork(IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fed2e7-7404-4a3b-8629-6083842e3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(network, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b56644-fdfe-4608-a0cf-c468db7310ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc12db-928c-4629-bb64-0a9b6c572819",
   "metadata": {},
   "outputs": [],
   "source": [
    "results=model.predict(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b97f82b-7049-44c5-acf1-f704baad9493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(results):\n",
    "    df = pd.DataFrame(results).transpose()\n",
    "    length=len(df)\n",
    "    df_agg = df.groupby(0)[1].agg(\n",
    "        _0=lambda x: (x == 0).sum(),\n",
    "        _1=lambda x: (x == 1).sum()\n",
    "    ).reset_index()\n",
    "\n",
    "    true_positives = df_agg[df_agg[0] == 1]['_1'].sum()  # True Positive\n",
    "    true_negatives = df_agg[df_agg[0] == 0]['_0'].sum()  # True Negative\n",
    "    false_positives = df_agg[df_agg[0] == 0]['_1'].sum()  # False Positive\n",
    "    false_negatives = df_agg[df_agg[0] == 1]['_0'].sum()  # False Negative\n",
    "\n",
    "    matrix = pd.DataFrame({\n",
    "        'True 0': [true_negatives, false_positives],\n",
    "        'True 1': [false_negatives, true_positives]\n",
    "    }, index=['Pred 0', 'Pred 1'])\n",
    "    \n",
    "    accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "    \n",
    "    return matrix, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6e4cb093-9b1b-4cb9-a751-782b78e37d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix, accuracy = confusion_matrix(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d521515-d469-4f0a-8778-3f7fa50e47ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True 0</th>\n",
       "      <th>True 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pred 0</th>\n",
       "      <td>18076</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pred 1</th>\n",
       "      <td>2924</td>\n",
       "      <td>47489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        True 0  True 1\n",
       "Pred 0   18076     511\n",
       "Pred 1    2924   47489"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "192c4602-6f6f-4f9a-88d7-eba163f66a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9502\n"
     ]
    }
   ],
   "source": [
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbca1a-45ec-4ab3-aea1-c604f1b3442e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
