{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea5abb8-37f7-4f50-aa31-d97d9bba7e91",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ef624d-fc84-4a53-9e6d-291f68c2b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from Preprocess import Process\n",
    "from NeuralNetworkDIY import ClassifierNetwork, Model\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86229287-fe04-47b7-84be-70862133e1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce29e2-f3bd-4546-a98b-c086fe09808e",
   "metadata": {},
   "source": [
    "# Parameters for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba70bb57-9fca-49dc-a9a5-482a7dfd5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = \"data/raw/140k faces\"\n",
    "PROCESSED_DIR = \"data/processed\"\n",
    "IMAGE_SIZE=(128,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3d7d9-22cb-4375-8fe5-f80f5e95ddcd",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa1a1c1-e505-468e-be4e-e19c9d0e3962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on fake\n",
      "{8000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 152/152 [23:51<00:00,  9.42s/it]\n",
      "Processing valid: 100%|██████████| 8/8 [01:09<00:00,  8.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on real\n",
      "{3500}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train: 100%|██████████| 67/67 [09:50<00:00,  8.82s/it]\n",
      "Processing valid: 100%|██████████| 4/4 [00:32<00:00,  8.22s/it]\n"
     ]
    }
   ],
   "source": [
    "process=Process(RAW_DIR, PROCESSED_DIR, IMAGE_SIZE, delete_process_dir=True, batch_size=1000, aug_amount=0, filters=False)\n",
    "process.run(0.95, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e4d71-78dd-4d6a-b6aa-069188c23c3e",
   "metadata": {},
   "source": [
    "# DataLoader and Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21abdd73-fc67-4085-88c6-698059ea38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.image_paths = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        transform = transforms.ToTensor()\n",
    "        \n",
    "        img= transform(img)\n",
    "        # Extract label from the filename (fake -> 1, real -> 0)\n",
    "        label = 1 if \"fake\" in os.path.basename(img_path).lower() else 0\n",
    "\n",
    "        return img, label, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2db67dc5-5aec-4e72-99ae-572fcf680ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomImageDataset(directory=f'{PROCESSED_DIR}/{IMAGE_SIZE[0]}/train/rgb')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1a777-5745-435a-9024-3786b1611ddd",
   "metadata": {},
   "source": [
    "# Creating the network, model, training, predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9286121d-f4ff-4c8f-a121-85026df1fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "network=ClassifierNetwork(IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45fed2e7-7404-4a3b-8629-6083842e3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(network, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9b56644-fdfe-4608-a0cf-c468db7310ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batches: 80\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbca1a-45ec-4ab3-aea1-c604f1b3442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'ADL_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a038aea-e99f-4058-86b4-0b9f4bbeda6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
