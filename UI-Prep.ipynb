{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea5abb8-37f7-4f50-aa31-d97d9bba7e91",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ef624d-fc84-4a53-9e6d-291f68c2b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from Preprocess import Process\n",
    "from NeuralNetworkDIY import ClassifierNetwork, Model\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86229287-fe04-47b7-84be-70862133e1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce29e2-f3bd-4546-a98b-c086fe09808e",
   "metadata": {},
   "source": [
    "# Parameters for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba70bb57-9fca-49dc-a9a5-482a7dfd5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = \"data/raw/140k faces\"\n",
    "PROCESSED_DIR = \"data/processed\"\n",
    "IMAGE_SIZE=(128,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3d7d9-22cb-4375-8fe5-f80f5e95ddcd",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa1a1c1-e505-468e-be4e-e19c9d0e3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process=Process(RAW_DIR, PROCESSED_DIR, IMAGE_SIZE, delete_process_dir=True, batch_size=1000, aug_amount=3, filters=False)\n",
    "# process.run(0.95, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e4d71-78dd-4d6a-b6aa-069188c23c3e",
   "metadata": {},
   "source": [
    "# DataLoader and Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21abdd73-fc67-4085-88c6-698059ea38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.image_paths = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        transform = transforms.ToTensor()\n",
    "        \n",
    "        img= transform(img)\n",
    "        # Extract label from the filename (fake -> 1, real -> 0)\n",
    "        label = 1 if \"fake\" in os.path.basename(img_path).lower() else 0\n",
    "\n",
    "        return img, label, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db67dc5-5aec-4e72-99ae-572fcf680ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomImageDataset(directory=f'{PROCESSED_DIR}/{IMAGE_SIZE[0]}/train/rgb')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1a777-5745-435a-9024-3786b1611ddd",
   "metadata": {},
   "source": [
    "# Creating the network, model, training, predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9286121d-f4ff-4c8f-a121-85026df1fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "network=ClassifierNetwork(IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45fed2e7-7404-4a3b-8629-6083842e3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(network, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9b56644-fdfe-4608-a0cf-c468db7310ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.7234056819767374\n",
      "Epoch 2/10, Loss: 0.44661855315725646\n",
      "Epoch 3/10, Loss: 0.33239736798426106\n",
      "Epoch 4/10, Loss: 0.2694991558483318\n",
      "Epoch 5/10, Loss: 0.22565780639716634\n",
      "Epoch 6/10, Loss: 0.19614586138616164\n",
      "Epoch 7/10, Loss: 0.17321705922177508\n",
      "Epoch 8/10, Loss: 0.15442254811150258\n",
      "Epoch 9/10, Loss: 0.13892722494678583\n",
      "Epoch 10/10, Loss: 0.12499064688722111\n"
     ]
    }
   ],
   "source": [
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00bbca1a-45ec-4ab3-aea1-c604f1b3442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'ADL_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a038aea-e99f-4058-86b4-0b9f4bbeda6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64f47f-3db5-4b73-bbe1-acb7b1ed2ded",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
