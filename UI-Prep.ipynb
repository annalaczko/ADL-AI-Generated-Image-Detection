{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea5abb8-37f7-4f50-aa31-d97d9bba7e91",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef624d-fc84-4a53-9e6d-291f68c2b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from Preprocess import Process\n",
    "from NeuralNetworkDIY import ClassifierNetwork, Model\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86229287-fe04-47b7-84be-70862133e1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce29e2-f3bd-4546-a98b-c086fe09808e",
   "metadata": {},
   "source": [
    "# Parameters for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70bb57-9fca-49dc-a9a5-482a7dfd5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = r\"C:\\Users\\annal\\ADL\\archive\\real-vs-fake\"\n",
    "PROCESSED_DIR = \"data/processed\"\n",
    "IMAGE_SIZE=(128,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3d7d9-22cb-4375-8fe5-f80f5e95ddcd",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa1a1c1-e505-468e-be4e-e19c9d0e3962",
   "metadata": {},
   "outputs": [],
   "source": [
    "process=Process(RAW_DIR, PROCESSED_DIR, IMAGE_SIZE, delete_process_dir=True, batch_size=1000, aug_amount=0)\n",
    "process.run(0.9, 0.1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e4d71-78dd-4d6a-b6aa-069188c23c3e",
   "metadata": {},
   "source": [
    "# DataLoader and Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21abdd73-fc67-4085-88c6-698059ea38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.image_paths = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        transform = transforms.ToTensor()\n",
    "        \n",
    "        img= transform(img)\n",
    "        # Extract label from the filename (fake -> 1, real -> 0)\n",
    "        label = 1 if \"fake\" in os.path.basename(img_path).lower() else 0\n",
    "\n",
    "        return img, label, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db67dc5-5aec-4e72-99ae-572fcf680ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomImageDataset(directory=f'{PROCESSED_DIR}/{IMAGE_SIZE[0]}/train/rgb')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1a777-5745-435a-9024-3786b1611ddd",
   "metadata": {},
   "source": [
    "# Creating the network, model, training, predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9286121d-f4ff-4c8f-a121-85026df1fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "network=ClassifierNetwork(IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45fed2e7-7404-4a3b-8629-6083842e3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(network, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9b56644-fdfe-4608-a0cf-c468db7310ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.1753672527970735\n",
      "Epoch 2/20, Loss: 0.6025866880920363\n",
      "Epoch 3/20, Loss: 0.5447155918393817\n",
      "Epoch 4/20, Loss: 0.46101849327176253\n",
      "Epoch 5/20, Loss: 0.36976973869785756\n",
      "Epoch 6/20, Loss: 0.2761201551241904\n",
      "Epoch 7/20, Loss: 0.2162919287911113\n",
      "Epoch 8/20, Loss: 0.16006820884920794\n",
      "Epoch 9/20, Loss: 0.12146590437207903\n",
      "Epoch 10/20, Loss: 0.09607401673005235\n",
      "Epoch 11/20, Loss: 0.07584814220574332\n",
      "Epoch 12/20, Loss: 0.06036167557102553\n",
      "Epoch 13/20, Loss: 0.04956029160006076\n",
      "Epoch 14/20, Loss: 0.04129925461034782\n",
      "Epoch 15/20, Loss: 0.035872503172212876\n",
      "Epoch 16/20, Loss: 0.03321911282374622\n",
      "Epoch 17/20, Loss: 0.02255662088137791\n",
      "Epoch 18/20, Loss: 0.024761361810407653\n",
      "Epoch 19/20, Loss: 0.02673747133093406\n",
      "Epoch 20/20, Loss: 0.01652910099335894\n"
     ]
    }
   ],
   "source": [
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbca1a-45ec-4ab3-aea1-c604f1b3442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'ADL_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
