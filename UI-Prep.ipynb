{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ea5abb8-37f7-4f50-aa31-d97d9bba7e91",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93ef624d-fc84-4a53-9e6d-291f68c2b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from Preprocess import Process\n",
    "from NeuralNetworkDIY import ClassifierNetwork, Model\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86229287-fe04-47b7-84be-70862133e1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ce29e2-f3bd-4546-a98b-c086fe09808e",
   "metadata": {},
   "source": [
    "# Parameters for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba70bb57-9fca-49dc-a9a5-482a7dfd5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DIR = r\"C:\\Users\\annal\\ADL\\archive\\real-vs-fake\"\n",
    "PROCESSED_DIR = \"data/processed\"\n",
    "IMAGE_SIZE=(128,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb3d7d9-22cb-4375-8fe5-f80f5e95ddcd",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa1a1c1-e505-468e-be4e-e19c9d0e3962",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] A hozzáférés megtagadva: 'data/processed\\\\128\\\\train\\\\rgb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m process\u001b[38;5;241m=\u001b[39mProcess(RAW_DIR, PROCESSED_DIR, IMAGE_SIZE, delete_process_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, aug_amount\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      2\u001b[0m process\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;241m0.9\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\OneDrive\\Dokumentumok\\GitHub\\ADL-AI-Generated-Image-Detection\\Preprocess.py:37\u001b[0m, in \u001b[0;36mProcess.__init__\u001b[1;34m(self, raw_dir, process_dir, image_size, delete_process_dir, batch_size, aug_amount)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Deleting the original processed_dir to make the new dataset\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m delete_process_dir \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPROCESSED_DIR):\n\u001b[1;32m---> 37\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mrmtree(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPROCESSED_DIR)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Defining transformations for the images\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresize_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     41\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mIMAGE_SIZE),\n\u001b[0;32m     42\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     43\u001b[0m ])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jupyterlab\\Lib\\shutil.py:781\u001b[0m, in \u001b[0;36mrmtree\u001b[1;34m(path, ignore_errors, onerror, onexc, dir_fd)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;66;03m# can't continue even if onexc hook returns\u001b[39;00m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _rmtree_unsafe(path, onexc)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jupyterlab\\Lib\\shutil.py:629\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onexc)\u001b[0m\n\u001b[0;32m    627\u001b[0m         os\u001b[38;5;241m.\u001b[39mrmdir(fullname)\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 629\u001b[0m         onexc(os\u001b[38;5;241m.\u001b[39mrmdir, fullname, err)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[0;32m    631\u001b[0m     fullname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirpath, name)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\jupyterlab\\Lib\\shutil.py:627\u001b[0m, in \u001b[0;36m_rmtree_unsafe\u001b[1;34m(path, onexc)\u001b[0m\n\u001b[0;32m    625\u001b[0m fullname \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirpath, name)\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 627\u001b[0m     os\u001b[38;5;241m.\u001b[39mrmdir(fullname)\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    629\u001b[0m     onexc(os\u001b[38;5;241m.\u001b[39mrmdir, fullname, err)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] A hozzáférés megtagadva: 'data/processed\\\\128\\\\train\\\\rgb'"
     ]
    }
   ],
   "source": [
    "process=Process(RAW_DIR, PROCESSED_DIR, IMAGE_SIZE, delete_process_dir=True, batch_size=1000, aug_amount=0)\n",
    "process.run(0.9, 0.1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e4d71-78dd-4d6a-b6aa-069188c23c3e",
   "metadata": {},
   "source": [
    "# DataLoader and Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21abdd73-fc67-4085-88c6-698059ea38a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.image_paths = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith((\".png\", \".jpg\", \".jpeg\"))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        transform = transforms.ToTensor()\n",
    "        \n",
    "        img= transform(img)\n",
    "        # Extract label from the filename (fake -> 1, real -> 0)\n",
    "        label = 1 if \"fake\" in os.path.basename(img_path).lower() else 0\n",
    "\n",
    "        return img, label, img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db67dc5-5aec-4e72-99ae-572fcf680ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomImageDataset(directory=f'{PROCESSED_DIR}/{IMAGE_SIZE[0]}/train/rgb')\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd1a777-5745-435a-9024-3786b1611ddd",
   "metadata": {},
   "source": [
    "# Creating the network, model, training, predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9286121d-f4ff-4c8f-a121-85026df1fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "network=ClassifierNetwork(IMAGE_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45fed2e7-7404-4a3b-8629-6083842e3188",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(network, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9b56644-fdfe-4608-a0cf-c468db7310ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 1.1753672527970735\n",
      "Epoch 2/20, Loss: 0.6025866880920363\n",
      "Epoch 3/20, Loss: 0.5447155918393817\n",
      "Epoch 4/20, Loss: 0.46101849327176253\n",
      "Epoch 5/20, Loss: 0.36976973869785756\n",
      "Epoch 6/20, Loss: 0.2761201551241904\n",
      "Epoch 7/20, Loss: 0.2162919287911113\n",
      "Epoch 8/20, Loss: 0.16006820884920794\n",
      "Epoch 9/20, Loss: 0.12146590437207903\n",
      "Epoch 10/20, Loss: 0.09607401673005235\n",
      "Epoch 11/20, Loss: 0.07584814220574332\n",
      "Epoch 12/20, Loss: 0.06036167557102553\n",
      "Epoch 13/20, Loss: 0.04956029160006076\n",
      "Epoch 14/20, Loss: 0.04129925461034782\n",
      "Epoch 15/20, Loss: 0.035872503172212876\n",
      "Epoch 16/20, Loss: 0.03321911282374622\n",
      "Epoch 17/20, Loss: 0.02255662088137791\n",
      "Epoch 18/20, Loss: 0.024761361810407653\n",
      "Epoch 19/20, Loss: 0.02673747133093406\n",
      "Epoch 20/20, Loss: 0.01652910099335894\n"
     ]
    }
   ],
   "source": [
    "model.train(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bbca1a-45ec-4ab3-aea1-c604f1b3442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'ADL_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
